<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.42" />
  <meta name="author" content="Tong Shen">

  
  
  
  
    
      
    
  
  <meta name="description" content="Introduction In late 2017, Geoffrey Hinton, one of the biggest names in deep learning community, finally published his work about capsule theory. Hintion has worked on this for years, like Transforming Auto-Encoders. This should be a big step for us to understand human brain.
CapsNet consists of many capsules. Rather than output a scalar, capsules output a vector. The length of the vector will represent the probability of certain entity and the vector itself will represent the property of this entity.">

  
  <link rel="alternate" hreflang="en-us" href="/post/capsnet-and-dynamic-routing/">

  


  

  
  
  <meta name="theme-color" content="#0095eb">
  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700%7cMerriweather%7cRoboto&#43;Mono%7cPermanent&#43;Marker%7cPrata">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Tong Shen">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Tong Shen">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/capsnet-and-dynamic-routing/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Tong Shen">
  <meta property="og:url" content="/post/capsnet-and-dynamic-routing/">
  <meta property="og:title" content="CapsNet and dynamic routing | Tong Shen">
  <meta property="og:description" content="Introduction In late 2017, Geoffrey Hinton, one of the biggest names in deep learning community, finally published his work about capsule theory. Hintion has worked on this for years, like Transforming Auto-Encoders. This should be a big step for us to understand human brain.
CapsNet consists of many capsules. Rather than output a scalar, capsules output a vector. The length of the vector will represent the probability of certain entity and the vector itself will represent the property of this entity.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-07-19T21:00:00-05:00">
  
  <meta property="article:modified_time" content="2018-07-19T21:00:00-05:00">
  

  
  

  <title>CapsNet and dynamic routing | Tong Shen</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Tong Shen</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#myself">
            
            <span>CV</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">CapsNet and dynamic routing</h1>

    

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2018-07-19 21:00:00 -0500 CDT" itemprop="datePublished dateModified">
      Jul 19, 2018
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Tong Shen">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    10 min read
  </span>
  

  
  

  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=CapsNet%20and%20dynamic%20routing&amp;url=%2fpost%2fcapsnet-and-dynamic-routing%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fcapsnet-and-dynamic-routing%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fcapsnet-and-dynamic-routing%2f&amp;title=CapsNet%20and%20dynamic%20routing"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fcapsnet-and-dynamic-routing%2f&amp;title=CapsNet%20and%20dynamic%20routing"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=CapsNet%20and%20dynamic%20routing&amp;body=%2fpost%2fcapsnet-and-dynamic-routing%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


    <div class="article-style" itemprop="articleBody">
      

<h2 id="introduction">Introduction</h2>

<p>In late 2017, Geoffrey Hinton, one of the biggest names in deep learning community, finally published his work about capsule theory. Hintion has worked on this for years, like <a href="http://www.cs.toronto.edu/~fritz/absps/transauto6.pdf" target="_blank">Transforming Auto-Encoders</a>. This should be a big step for us to understand human brain.</p>

<p><a href="https://arxiv.org/pdf/1710.09829.pdf" target="_blank">CapsNet</a> consists of many capsules. Rather than output a scalar, capsules output a vector. The length of the vector will represent the probability of certain entity and the vector itself will represent the property of this entity. These properties can include many different types of instantiation parameter such as pose (position, size, orientation), deformation, velocity, albedo, hue, texture, etc. Also, high level can only be activated when two or more lower level capsules predictions agree with each other, while CNN high layer only preserve big activations from lower layer.</p>

<p>This vector agreement immediately remind me of the attention mechanism I previously used in seq2seq models and object localization models. Attention mechanism also use vector agreement, like dot product, to measure the weight of previous output(seq2seq)/different part of image(object localization), and use the weighted version as input for the next step. And this perspective is also mentioned in the paper:</p>

<blockquote>
<p>Dynamic routing can be viewed as a parallel attention mechanism that allows each capsule at one
level to attend to some active capsules at the level below and to ignore others.</p>
</blockquote>

<p>But why CapsNet works? We need to start from the drawback of CNN.</p>

<h2 id="problems-with-cnn">Problems with CNN</h2>

<blockquote>
<p>“The pooling operation used in convolutional neural networks is a big mistake and the fact that it works so well is a disaster.” &ndash; Hinton</p>
</blockquote>

<p>Based on the argument of Hinton, the main problem of convolutional neural network lies in max pooling layer. Maxpooling layers in CNN are used to squeeze the size of feature map, reduce its dimensionality and push the CNN to represent original image into another persperctive. Also, it can make the higher level neurons have larger receptive field to mkae semantic prediction. However it will lose a lot of valuable information, like the <strong>exact location information</strong> of object in the image.</p>

<p>For example, assume we have 5 maxpooling layer in a network, and an object in a 32x32 block of input image. In this way, no matter how we move the object in the image, there will be no change in the final feature map. This will cause problems. The network not cares about what the object is, rather than where the object lies. So, if different parts of an object move a little bit, CNN will stay the same. Here is a famous picture illustrating this point:</p>

<p><img src="/img/capsnet_face.png" alt="" /></p>

<p>Every part of human face is tweaked, but CNN still recognizes it as human face. Real world situation is not so extreme, but this example can give us an intuition of this.</p>

<p>Additionally, CNNs cannot handle <strong>rotation</strong> at all - if they are trained on objects in one orientation, they will have trouble when the orientation is changed. According to Hinton, CNNs cannot do ‘handedness’ detection at all, even in principle. In other words, CNNs could never tell a left shoe from a right shoe, even if they were trained on both. Also, human visual system also has this drawback. Human vision system appears to impose a rectangular coordinate frames on objects. If an object is not placed along to the coordinate, people have to mentally rotate it.</p>

<p><strong>But Capsnet has good ablity on rotations</strong>. Unlike neurons in the output layer of a CNN, a capsule outputs a probability of whether an entity is present, but additionally has pose information on it. And when calculating agreement, we only care about the relative agreement over different part. So the pose of object will also incorporate the pose information. This can also transform part pose to object pose. So, when using CapsNet, we may not need to rotate the image, the capsule output already take care of it.</p>

<p>According to Hinton, CNN is a very inefficient way of learning, in that it requires a lot of data. While CapsNet utilizes data in a more efficient way. When taking entity properties into account, it&rsquo;s like automatic data augmentation (My personal understanding).</p>

<p>To sum up, CNN&rsquo;s problems lies in two part:</p>

<ol>
<li>Lose concise location information to object parts and hierarchical pose relationships between object parts. Predict based on feature (activation) counting.</li>
<li>Impose a rectangular coordinate frames on objects. Make it hard to recognize affine transformed objects.</li>
</ol>

<h2 id="inverse-graphics">Inverse Graphics</h2>

<p>According to Hinton, the concept of CapsNet comes from the idea of inverse graphics. In computer graphics, if people want to render something, they will first render different parts, and use some vectors to put them in a proper <strong>relative location</strong>. This process is illustrated in the following figure (image <a href="https://jhui.github.io/2017/11/03/Dynamic-Routing-Between-Capsules/" target="_blank">source</a>):</p>

<p><img src="/img/inverse_graphics.jpg" alt="inverse_graphics" /></p>

<p>In computer graphics, people do it in the top-down way. For inverse graphics, we need to do it in a bottom-up fashion. First, we detect different small parts and their propertis, represented in the capsule output. And then, if the output &ldquo;agrees&rdquo;, it is reversely equivalent to the process in graphics that assembling different part into a bigger object. So, lower level capsules are more concise for entity location and high-level capsules are more about sementic information, which is the same to CNNs. In the paper, Hinton called the lower level capsule &ldquo;place-encoded&rdquo; and the higher-level capsules &ldquo;rate-encoded&rdquo;.</p>

<p>The most important part of CapsNet is routed by &ldquo;agreement&rdquo; between capsules. We only care about the <strong>relative</strong> relationship between capsules. So, the higher level capsules only cares about whether lower level capsules agree or not, rather than what exact consists in the capsule. This is kind of like graphics, rended object is not related to view angle. This can address CNN&rsquo;s weakness in affine transforms like rotation. Capsule will treat the liberty statue in different pictures equally.</p>

<p><img src="/img/statue.jpg" alt="statue" /></p>

<p>Also, for occluded object, CapsNet only need the agreement of some parts of an object to predict the object, rather than counting feature appearance to predict the object in CNN. Also, if two objects are overlapped, their feature map in CNN may inference each other, and make prediction inaccurate, while CapsNet can avoid this with &ldquo;agreement routing&rdquo;. So CapsNet has advantage on recognize partly showed object in images, like the occluded faces in the following image (<a href="http://www.lce.hut.fi/research/eas/object/" target="_blank">source</a>).</p>

<p><img src="/img/occluded_face.png" alt="occluded_face" /></p>

<p>Based on my understanding, the inverse graphics idea is quite interesting and mind blowing.</p>

<p>But I want to say, CNN also cannot analyze the image in 3D space that objects actually lies in. In computer graphics, people always construct object in a 3D sapce and project it on screen as images. Why not push inverse graphics to the limit, make it exactly the inverse of graphics? I believe the next generation of CNNs would be the breakthrough of 3D reconstruction.</p>

<h2 id="capsnet-architecture">CapsNet architecture</h2>

<h3 id="iterative-dynamic-routing">Iterative Dynamic Routing</h3>

<p>At first, we don&rsquo;t know the weight of each capsule to calculate next layer of capsules. So, the initial value of the weight is all zero.</p>

<p>$$b_{ij} \leftarrow 0$$</p>

<p>In this article, all the lower right corner indexes, like $b_{ij}$, means the parameter to calculate higher level capsules $j$ with lower level capsule $i$&rsquo;s output.</p>

<p>So, with the weight of all lower capsules, we need a softmax to normalize it, just like what we do in CNNs. When calculating $j-th$ capsule in higher layer, we get:</p>

<p>$$c_i = softmax(b_i)$$</p>

<p>And the output of every capsule, $u_i$, need to go through a transformation:</p>

<p>$$\hat{u}_{j|i} = W_{ij} * u_i$$</p>

<p>We need to apply the softmax weight on the capsule output, which will be the input of next layer:</p>

<p>$$s_j \leftarrow \sum_i c_{ij} \hat{u}_{j|i} $$</p>

<p>The nonlinearity of CapsNet comes from the squash operation. Each capsule will simply squash long capsule input to 1 length, and squash short capsule input to 0, following this formula:</p>

<p>$$v_j = \frac{||s_j||^2}{1+||s_j||^2} \frac{s_j}{||s_j||}$$</p>

<p>And after each iteration, we accumulatively add $a_{ij}$ to $b_{ij}$:</p>

<p>$$b_{ij} \leftarrow b_{ij} + a_{ij}$$</p>

<p>where $a_{ij}$ is equal to  $\hat{u}_{j|i} * v_j$, simple dot product of last layers capsule output and current layers output.</p>

<p>$$b_{ij} \leftarrow b_{ij} + \hat{u}_{j|i} v_j$$</p>

<p>So, every higher layer capsule is trying to select certain lower layer capsules, whose output vector has a bigger dot product (agreement measure) with higher capsule&rsquo;s own output. Note there would be a lot of other ways to do this routing by agreement thing as well.</p>

<p>The overall algorithm goes like this:</p>

<p><img src="/img/dynamic_routing.png" alt="dynamic routing" /></p>

<h3 id="loss-function">Loss function</h3>

<p>CapsNet uses margin loss for digit existence. The top-level capsules are responsible to present the existence of digits. And also, the loss function should talk care multi-digit cases. The loss function goes like:</p>

<p><img src="/img/lossfunction.png" alt="marginloss" /></p>

<p>where $T_k = 1$ iff a digit of class k is present
and $m^+$ = 0.9 and $m^-$ = 0.1. The λ down weighting
of the loss for absent digit classes stops the initial learning from shrinking the lengths of the activity
vectors of all the digit capsules. We use λ = 0.5. The total loss is simply the sum of the losses of all
digit capsules.</p>

<p>And also, they use an additional reconstruction loss to encourage the digit capsules to encode the instantiation
parameters of the input digit. The reconstruction is quite simple:</p>

<p><img src="/img/capsnet_reconstruction.png" alt="" /></p>

<h3 id="architecture">Architecture</h3>

<p>The overall architecture of CapsNet is quite straightforward. Just copy from the paper:</p>

<p><strong>First layer is just like CNNs</strong>: Conv1 has 256, 9 × 9 convolution kernels with a
stride of 1 and ReLU activation. This layer converts pixel intensities to the activities of local feature
detectors that are then used as inputs to the primary capsules.</p>

<p><strong>Second layer is a preparation of Routing (output vectors):</strong> The second layer (PrimaryCapsules) is a convolutional capsule layer with 32 channels of convolutional 8D capsules (i.e. each primary capsule contains 8 convolutional units with a 9 × 9 kernel and a stride
of 2)</p>

<p><strong>Third layer is DigitCaps layer:</strong> It has one 16D capsule per digit class and each of these
capsules receives input from all the capsules in the layer below. Dynamic routing is implemented between PrimaryCapsules layer and DigitCaps layer.</p>

<p>Overall diagram is as follows:</p>

<p><img src="/img/capsnet.png" alt="capsNet" /></p>

<h2 id="result-comparasion">Result comparasion</h2>

<p>I just want to analyze this figure:</p>

<p><img src="/img/capsnet_result.png" alt="capsNet" /></p>

<p>We can clearly see CapsNet surpasses the state-of-the-art network. Amusingly, the improvement from reconstruction loss is larger than capsules and dynamic routing&hellip;</p>

<h2 id="advantages">Advantages</h2>

<p><strong>Robust to affine transform</strong></p>

<p>Experiments show that each DigitCaps capsule learns a more robust representation for each class
than a traditional convolutional network. Because there is natural variance in skew, rotation, style, etc
in hand written digits, the trained CapsNet is moderately robust to small affine transformations of the
training data.</p>

<p><strong>Interpretability</strong></p>

<p>The dimensions of a
digit capsule should learn to span the space of variations in the way digits of that class are instantiated.
These variations include stroke thickness, skew and width. They also include digit-specific variations
such as the length of the tail of a 2.  After computing the activity vector for the correct digit capsule, we can
feed a perturbed version of this activity vector to the decoder network and see how the perturbation
affects the reconstruction. We can find that one
dimension (out of 16) of the capsule almost always represents the width of the digit. While some
dimensions represent combinations of global variations, there are other dimensions that represent variation in a localized part of the digit. For example, different dimensions are used for the length of
the ascender of a 6 and the size of the loop.</p>

<p><img src="/img/CapsNet_inter.png" alt="capsNet" /></p>

<h2 id="problems">Problems</h2>

<p><strong>Computational cost</strong></p>

<p>The biggest problem of dynamic routing is of course the computational cost. For each higher level capsule, we need to calculate its agreement with all the lower layer capsules. The complexity is huge (O(N^3)). And that is also the main reason that Capsnet can only used in simple dataset like smallNORB, MNIST. In these dataset, the dimension of single capsule, as well as the network width, do not need to be very large.</p>

<p>So, the next step must be more advanced and efficient routing method. Lucklily, we already have one now: <a href="https://openreview.net/pdf?id=HJWLfGWRb" target="_blank">EM routing</a></p>

<h2 id="em-routing">EM routing</h2>

<h3 id="implementation">Implementation</h3>

<h3 id="result">Result</h3>

<h2 id="sum-up">Sum up</h2>

<p>To sum up, the advantage of CapsNet has two folders:</p>

<ol>
<li>Instead of output a scalar in a neuron, capsules output a vector to encode the properties of an entity, like pose (position, size, orientation), deformation, velocity, albedo, hue, texture, etc.</li>
<li>With a vector output, higher layers are able to choose any lower capsule as input. While in CNN, their input neurons are fixed.</li>
</ol>

<h2 id="reference-materials">Reference materials</h2>

<ol>
<li><a href="https://arxiv.org/pdf/1710.09829.pdf" target="_blank">Dynamic Routing Between Capsules</a></li>
<li><a href="https://openreview.net/pdf?id=HJWLfGWRb" target="_blank">MATRIX CAPSULES WITH EM ROUTING</a></li>
<li><a href="http://moreisdifferent.com/2017/09/hinton-whats-wrong-with-CNNs" target="_blank">Hinton: What&rsquo;s wrong with CNNs</a></li>
<li>[]</li>
</ol>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/spatial-transformer/">Spatial transformer</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/deep-learning/">deep learning</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/tensorflow/">tensorflow</a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/nlp-basics---word2vec/">NLP basics - Word2vec: Skip-gram, CBOW, GloVe</a></li>
        
        <li><a href="/post/going-deeper-into-batch-normalization/">Going Deeper in Batch Normalization</a></li>
        
        <li><a href="/post/amazing-gan---wasserstein-gan/">Amazing GAN - Wasserstein GAN</a></li>
        
        <li><a href="/post/neural-network-based-object-recognition-fast-faster-mask-r-cnn-ssd-and-yolo/">Neural Network based Object Recognition: Fast/Faster/Mask R-CNN, SSD, YOLO and RetinaNet</a></li>
        
      </ul>
    </div>
    

    

    


  </div>
</article>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 &middot; 

      Powered by
      
      <a href="https://shen338.github.io/" target="_blank" rel="noopener">Tong Shen</a>. 
	  
	  All rights reserved.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

